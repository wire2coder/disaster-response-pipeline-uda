{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cnnicentral2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cnnicentral2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cnnicentral2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# punkt is a tokenizer that is used to split text into individual words and sentences.\n",
    "# wordnet is a lexical database of English words that is used for \n",
    "# various NLP tasks such as stemming, lemmatization, and synonym detection.\n",
    "# nltk.download(['punkt', 'wordnet']);\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///ETL_Preparation.db')\n",
    "df = pd.read_sql_table('ETL_Preparation', engine)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>3395</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>...</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>6643</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>...</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "      <td>19906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>132</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  message  original  genre  request  offer  aid_related  \\\n",
       "related                                                                 \n",
       "0         6122     6122      3395   6122     6122   6122         6122   \n",
       "1        19906    19906      6643  19906    19906  19906        19906   \n",
       "2          188      188       132    188      188    188          188   \n",
       "\n",
       "         medical_help  medical_products  search_and_rescue  ...  aid_centers  \\\n",
       "related                                                     ...                \n",
       "0                6122              6122               6122  ...         6122   \n",
       "1               19906             19906              19906  ...        19906   \n",
       "2                 188               188                188  ...          188   \n",
       "\n",
       "         other_infrastructure  weather_related  floods  storm   fire  \\\n",
       "related                                                                \n",
       "0                        6122             6122    6122   6122   6122   \n",
       "1                       19906            19906   19906  19906  19906   \n",
       "2                         188              188     188    188    188   \n",
       "\n",
       "         earthquake   cold  other_weather  direct_report  \n",
       "related                                                   \n",
       "0              6122   6122           6122           6122  \n",
       "1             19906  19906          19906          19906  \n",
       "2               188    188            188            188  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('related').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>3395</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>...</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "      <td>6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>6775</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>...</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "      <td>20094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  message  original  genre  request  offer  aid_related  \\\n",
       "related                                                                 \n",
       "0         6122     6122      3395   6122     6122   6122         6122   \n",
       "1        20094    20094      6775  20094    20094  20094        20094   \n",
       "\n",
       "         medical_help  medical_products  search_and_rescue  ...  aid_centers  \\\n",
       "related                                                     ...                \n",
       "0                6122              6122               6122  ...         6122   \n",
       "1               20094             20094              20094  ...        20094   \n",
       "\n",
       "         other_infrastructure  weather_related  floods  storm   fire  \\\n",
       "related                                                                \n",
       "0                        6122             6122    6122   6122   6122   \n",
       "1                       20094            20094   20094  20094  20094   \n",
       "\n",
       "         earthquake   cold  other_weather  direct_report  \n",
       "related                                                   \n",
       "0              6122   6122           6122           6122  \n",
       "1             20094  20094          20094          20094  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  this code is to replace any occurrence of the value 2 in the related column with the value 1.\n",
    "# because the value 2 'so small' in the 'related' column\n",
    "df['related']=df['related'].map(lambda x: 1 if x == 2 else x)\n",
    "df.groupby('related').count() # 19906 + 188 = 20094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y variables from the data for the modelling\n",
    "X = df['message']\n",
    "y = df.iloc[:,4:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, url_place_holder_string=\"urlplaceholder\"):\n",
    "    \n",
    "    # Replace all urls with a urlplaceholder string\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    # Extract all the urls from the provided text \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # Replace url with a url placeholder string\n",
    "    for detected_url in detected_urls:\n",
    "        text = text.replace(detected_url, url_place_holder_string)\n",
    "\n",
    "    # Extract the word tokens from the provided text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # 'Lemmanitizer' is used to reduce words to the 'root word'\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    # List of clean tokens\n",
    "    clean_tokens = [lemmatizer.lemmatize(w).lower().strip() for w in tokens]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The InitialVerbDetector class is a custom scikit-learn transformer that identifies if any sentence\n",
    "# within a given text starts with a verb. It inherits from BaseEstimator and TransformerMixin and\n",
    "# implements the fit() and transform() methods. The main function, detect_initial_verb(), tokenizes\n",
    "# the input text into sentences and then checks the part-of-speech (POS) tag of the first word in each\n",
    "# sentence. If the POS tag is 'VB' (base form verb) or 'VBP' (non-3rd person singular present verb),\n",
    "# or if the first word is 'RT' (usually indicating a retweet on Twitter), it returns True. Otherwise,\n",
    "# it returns False. This transformer can be useful in various natural language processing tasks, such\n",
    "# as sentiment analysis or text classification.\n",
    "\n",
    "class InitialVerbDetector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def detect_initial_verb(self, input_text):\n",
    "        sentences = nltk.sent_tokenize(input_text)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            initial_word, initial_tag = pos_tags[0]\n",
    "\n",
    "            if initial_tag in ['VB', 'VBP'] or initial_word == 'RT':\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def transform(self, input_data):\n",
    "        tagged_data = pd.Series(input_data).apply(self.detect_initial_verb)\n",
    "        return pd.DataFrame(tagged_data)\n",
    "\n",
    "    # Implements the scikit-learn transformer interface by returning 'self'\n",
    "    def fit(self, input_data, target_data=None):\n",
    "        return self\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ]))\n",
    "            \n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb_transformer', InitialVerbDetector() )\n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline using scikit-learn library. The pipeline consists of two main components:\n",
    "\n",
    "- FeatureUnion: This component allows combining multiple feature extraction methods. In this example, it includes only one feature extraction method - text_pipeline.\n",
    "\n",
    "- MultiOutputClassifier: This is a wrapper for multi-output classification algorithms. In this example, it uses the AdaBoostClassifier algorithm for multi-output classification.\n",
    "\n",
    "The text_pipeline feature extraction method consists of two sub-components:\n",
    "\n",
    "- CountVectorizer: This is used to convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "- TfidfTransformer: This is used to transform a count matrix to a normalized term-frequency times inverse document-frequency representation.\n",
    "\n",
    "The pipeline is designed to handle multi-output classification problems, meaning that it can predict multiple target variables at the same time. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y)\n\u001b[1;32m----> 2\u001b[0m pipeline_fitted \u001b[39m=\u001b[39m pipe1\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      3\u001b[0m \u001b[39m# joblib.dump(pipeline_fitted, 'pipeline_fitted.pkl') # save the 'pipeline_fitted' to a file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39m# 'train' making 'equations'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# 1754_SatApril2023, about 2 minutes\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# 1915_SatApril2023, about 3 minutes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, Y, sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    217\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    220\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    221\u001b[0m )\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:162\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    159\u001b[0m sample_weight[zero_weight_mask] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    161\u001b[0m \u001b[39m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[0;32m    163\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[0;32m    164\u001b[0m )\n\u001b[0;32m    166\u001b[0m \u001b[39m# Early termination\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:569\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 569\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    571\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    572\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:578\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    576\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m--> 578\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m    580\u001b[0m y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    582\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cnnicentral2\\JUNO\\PYTHONG\\disaster-response-pipeline-uda\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = pipe1.fit(X_train, y_train)\n",
    "# joblib.dump(pipeline_fitted, 'pipeline_fitted.pkl') # save the 'pipeline_fitted' to a file\n",
    "\n",
    "# 'train' making 'equations'\n",
    "# 1754_SatApril2023, about 2 minutes\n",
    "# 1915_SatApril2023, about 3 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.82      0.95      0.88      5000\n",
      "               request       0.77      0.53      0.63      1143\n",
      "                 offer       0.18      0.08      0.11        24\n",
      "           aid_related       0.74      0.60      0.67      2680\n",
      "          medical_help       0.54      0.26      0.35       508\n",
      "      medical_products       0.61      0.33      0.43       332\n",
      "     search_and_rescue       0.60      0.20      0.30       176\n",
      "              security       0.35      0.06      0.10       109\n",
      "              military       0.58      0.34      0.43       199\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.71      0.65      0.68       436\n",
      "                  food       0.79      0.69      0.74       711\n",
      "               shelter       0.77      0.54      0.64       585\n",
      "              clothing       0.64      0.36      0.46        98\n",
      "                 money       0.56      0.28      0.37       171\n",
      "        missing_people       0.58      0.21      0.31        72\n",
      "              refugees       0.51      0.24      0.33       217\n",
      "                 death       0.78      0.51      0.62       303\n",
      "             other_aid       0.50      0.12      0.20       872\n",
      "infrastructure_related       0.47      0.10      0.16       449\n",
      "             transport       0.56      0.27      0.37       285\n",
      "             buildings       0.60      0.37      0.46       315\n",
      "           electricity       0.61      0.25      0.35       142\n",
      "                 tools       0.29      0.05      0.09        38\n",
      "             hospitals       0.31      0.07      0.12        70\n",
      "                 shops       0.00      0.00      0.00        31\n",
      "           aid_centers       0.50      0.11      0.18        91\n",
      "  other_infrastructure       0.45      0.10      0.16       302\n",
      "       weather_related       0.84      0.66      0.74      1826\n",
      "                floods       0.87      0.53      0.66       569\n",
      "                 storm       0.75      0.54      0.63       590\n",
      "                  fire       0.65      0.26      0.37        84\n",
      "            earthquake       0.88      0.77      0.82       616\n",
      "                  cold       0.64      0.33      0.43       126\n",
      "         other_weather       0.58      0.17      0.26       333\n",
      "         direct_report       0.72      0.48      0.57      1251\n",
      "\n",
      "             micro avg       0.77      0.59      0.66     20754\n",
      "             macro avg       0.58      0.33      0.41     20754\n",
      "          weighted avg       0.73      0.59      0.63     20754\n",
      "           samples avg       0.64      0.51      0.52     20754\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# load the saved pipeline from file\n",
    "# pipeline_fitted = joblib.load('pipeline_fitted.pkl')\n",
    "\n",
    "y_prediction_train = pipeline_fitted.predict(X_train)\n",
    "y_prediction_test = pipeline_fitted.predict(X_test)\n",
    "\n",
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model (Using GridSearchCV)\n",
    "Use GridSearchCV search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                                         CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                                                        (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__estimator__learning_rate&#x27;: [0.03],\n",
       "                         &#x27;classifier__estimator__n_estimators&#x27;: [13]},\n",
       "             scoring=&#x27;f1_micro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                                         CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                                                        (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__estimator__learning_rate&#x27;: [0.03],\n",
       "                         &#x27;classifier__estimator__n_estimators&#x27;: [13]},\n",
       "             scoring=&#x27;f1_micro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                  CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                                 (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                 CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                (&#x27;tfidf_transformer&#x27;,\n",
       "                                                 TfidfTransformer())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>text_pipeline</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=AdaBoostClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                         CountVectorizer(tokenizer=<function tokenize at 0x7f30448428c0>)),\n",
       "                                                                                        ('tfidf_transformer',\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__estimator__learning_rate': [0.03],\n",
       "                         'classifier__estimator__n_estimators': [13]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "parameters_grid1 = {'classifier__estimator__learning_rate': [0.03],\n",
    "              'classifier__estimator__n_estimators': [13]}\n",
    "\n",
    "\n",
    "# 'f1_micro' is used as the evaluation metric, which is a common metric used for multiclass classification problems.\n",
    "#  -1 is used to use all available CPU cores.\n",
    "cv = GridSearchCV(pipe1, param_grid=parameters_grid1, scoring='f1_micro', n_jobs=-1)\n",
    "cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                                         CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                                                        (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__estimator__learning_rate&#x27;: [0.03],\n",
       "                         &#x27;classifier__estimator__n_estimators&#x27;: [13]},\n",
       "             scoring=&#x27;f1_micro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                                         CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                                                        (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__estimator__learning_rate&#x27;: [0.03],\n",
       "                         &#x27;classifier__estimator__n_estimators&#x27;: [13]},\n",
       "             scoring=&#x27;f1_micro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                  CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                                 (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                 CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)),\n",
       "                                                (&#x27;tfidf_transformer&#x27;,\n",
       "                                                 TfidfTransformer())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>text_pipeline</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x7f30448428c0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=AdaBoostClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                         CountVectorizer(tokenizer=<function tokenize at 0x7f30448428c0>)),\n",
       "                                                                                        ('tfidf_transformer',\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__estimator__learning_rate': [0.03],\n",
       "                         'classifier__estimator__n_estimators': [13]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (cv) will contain the best hyperparameters found during the search, \n",
    "# and other information about the search process.\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__estimator__learning_rate': 0.03, 'classifier__estimator__n_estimators': 13}\n"
     ]
    }
   ],
   "source": [
    "# this doesn't make any sense\n",
    "print(cv.best_params_)\n",
    "\n",
    "# Get the prediction values from the 'grid search thing'\n",
    "y_prediction_test = cv.predict(X_test)\n",
    "y_prediction_train = cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19662, 36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction_test.shape # (6554, 36) rows, 36 columns\n",
    "y_prediction_train.shape # (19662, 36) rows, 36 columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.76      1.00      0.87      5000\n",
      "               request       0.87      0.24      0.38      1143\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.80      0.18      0.30      2680\n",
      "          medical_help       0.60      0.01      0.02       508\n",
      "      medical_products       0.75      0.01      0.02       332\n",
      "     search_and_rescue       0.63      0.19      0.30       176\n",
      "              security       0.00      0.00      0.00       109\n",
      "              military       0.00      0.00      0.00       199\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.57      0.83      0.67       436\n",
      "                  food       0.76      0.66      0.71       711\n",
      "               shelter       0.85      0.31      0.45       585\n",
      "              clothing       0.50      0.01      0.02        98\n",
      "                 money       1.00      0.01      0.01       171\n",
      "        missing_people       0.76      0.35      0.48        72\n",
      "              refugees       0.67      0.01      0.02       217\n",
      "                 death       1.00      0.01      0.03       303\n",
      "             other_aid       0.00      0.00      0.00       872\n",
      "infrastructure_related       0.00      0.00      0.00       449\n",
      "             transport       0.52      0.25      0.33       285\n",
      "             buildings       0.79      0.08      0.15       315\n",
      "           electricity       0.56      0.04      0.07       142\n",
      "                 tools       0.00      0.00      0.00        38\n",
      "             hospitals       0.00      0.00      0.00        70\n",
      "                 shops       0.00      0.00      0.00        31\n",
      "           aid_centers       0.00      0.00      0.00        91\n",
      "  other_infrastructure       0.00      0.00      0.00       302\n",
      "       weather_related       0.91      0.22      0.36      1826\n",
      "                floods       0.90      0.33      0.48       569\n",
      "                 storm       0.73      0.27      0.40       590\n",
      "                  fire       0.00      0.00      0.00        84\n",
      "            earthquake       0.89      0.64      0.74       616\n",
      "                  cold       0.50      0.05      0.09       126\n",
      "         other_weather       0.67      0.01      0.01       333\n",
      "         direct_report       0.63      0.40      0.49      1251\n",
      "\n",
      "             micro avg       0.76      0.42      0.54     20754\n",
      "             macro avg       0.49      0.17      0.21     20754\n",
      "          weighted avg       0.69      0.42      0.44     20754\n",
      "           samples avg       0.71      0.43      0.48     20754\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 'classification_report' for the 'test data'\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.77      1.00      0.87     15094\n",
      "               request       0.85      0.24      0.37      3331\n",
      "                 offer       1.00      0.01      0.02        94\n",
      "           aid_related       0.80      0.19      0.31      8180\n",
      "          medical_help       0.88      0.01      0.02      1576\n",
      "      medical_products       0.67      0.00      0.01       981\n",
      "     search_and_rescue       0.64      0.18      0.28       548\n",
      "              security       0.00      0.00      0.00       362\n",
      "              military       0.40      0.00      0.01       661\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.58      0.85      0.69      1236\n",
      "                  food       0.78      0.68      0.73      2212\n",
      "               shelter       0.84      0.29      0.43      1729\n",
      "              clothing       1.00      0.00      0.01       307\n",
      "                 money       0.00      0.00      0.00       433\n",
      "        missing_people       0.63      0.23      0.34       226\n",
      "              refugees       0.82      0.01      0.03       658\n",
      "                 death       0.62      0.01      0.01       891\n",
      "             other_aid       0.00      0.00      0.00      2574\n",
      "infrastructure_related       0.00      0.00      0.00      1256\n",
      "             transport       0.60      0.25      0.35       916\n",
      "             buildings       0.79      0.09      0.17      1018\n",
      "           electricity       0.71      0.05      0.10       390\n",
      "                 tools       0.00      0.00      0.00       121\n",
      "             hospitals       0.00      0.00      0.00       213\n",
      "                 shops       0.00      0.00      0.00        89\n",
      "           aid_centers       0.00      0.00      0.00       218\n",
      "  other_infrastructure       0.00      0.00      0.00       849\n",
      "       weather_related       0.91      0.22      0.36      5471\n",
      "                floods       0.92      0.34      0.50      1586\n",
      "                 storm       0.74      0.25      0.38      1853\n",
      "                  fire       0.00      0.00      0.00       198\n",
      "            earthquake       0.90      0.65      0.76      1839\n",
      "                  cold       0.65      0.03      0.06       404\n",
      "         other_weather       0.57      0.00      0.01      1043\n",
      "         direct_report       0.63      0.38      0.48      3824\n",
      "\n",
      "             micro avg       0.76      0.42      0.54     62381\n",
      "             macro avg       0.52      0.17      0.20     62381\n",
      "          weighted avg       0.70      0.42      0.44     62381\n",
      "           samples avg       0.72      0.43      0.49     62381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 'classification_report' for the 'train data'\n",
    "print(classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# using pipe2 which includes StartingVerbEstimator\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = pipe2.fit(X_train, y_train)\n",
    "\n",
    "# 0306_MonApril2023, about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction/guessing from 'pipe2'\n",
    "y_prediction_from_train_data = pipeline_fitted.predict(X_train)\n",
    "y_prediction_from_test_data = pipeline_fitted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.95      0.88     15049\n",
      "               request       0.80      0.56      0.66      3348\n",
      "                 offer       0.52      0.13      0.21        82\n",
      "           aid_related       0.77      0.60      0.67      8126\n",
      "          medical_help       0.67      0.29      0.41      1597\n",
      "      medical_products       0.70      0.35      0.46       976\n",
      "     search_and_rescue       0.71      0.22      0.34       546\n",
      "              security       0.45      0.09      0.16       373\n",
      "              military       0.67      0.34      0.46       644\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.79      0.63      0.70      1265\n",
      "                  food       0.81      0.68      0.74      2177\n",
      "               shelter       0.80      0.55      0.65      1732\n",
      "              clothing       0.78      0.51      0.62       314\n",
      "                 money       0.66      0.35      0.45       446\n",
      "        missing_people       0.68      0.19      0.30       213\n",
      "              refugees       0.64      0.23      0.34       653\n",
      "                 death       0.77      0.51      0.61       883\n",
      "             other_aid       0.57      0.17      0.27      2552\n",
      "infrastructure_related       0.52      0.10      0.17      1305\n",
      "             transport       0.67      0.25      0.37       927\n",
      "             buildings       0.70      0.42      0.53      1048\n",
      "           electricity       0.70      0.32      0.44       397\n",
      "                 tools       0.38      0.07      0.11       122\n",
      "             hospitals       0.59      0.14      0.23       212\n",
      "                 shops       0.60      0.07      0.12        86\n",
      "           aid_centers       0.51      0.13      0.21       239\n",
      "  other_infrastructure       0.46      0.09      0.16       890\n",
      "       weather_related       0.86      0.67      0.75      5509\n",
      "                floods       0.88      0.56      0.68      1664\n",
      "                 storm       0.79      0.50      0.61      1809\n",
      "                  fire       0.73      0.31      0.44       216\n",
      "            earthquake       0.89      0.79      0.84      1861\n",
      "                  cold       0.78      0.40      0.53       406\n",
      "         other_weather       0.58      0.18      0.28      1016\n",
      "         direct_report       0.76      0.49      0.60      3778\n",
      "\n",
      "             micro avg       0.80      0.60      0.68     62461\n",
      "             macro avg       0.67      0.36      0.44     62461\n",
      "          weighted avg       0.77      0.60      0.65     62461\n",
      "           samples avg       0.65      0.52      0.53     62461\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print the 'accuracy report' for the 'train data'\n",
    "print(classification_report(y_train.values, y_prediction_from_train_data, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88      5045\n",
      "               request       0.76      0.54      0.63      1126\n",
      "                 offer       0.00      0.00      0.00        36\n",
      "           aid_related       0.78      0.60      0.68      2734\n",
      "          medical_help       0.55      0.26      0.36       487\n",
      "      medical_products       0.66      0.32      0.44       337\n",
      "     search_and_rescue       0.64      0.22      0.33       178\n",
      "              security       0.25      0.05      0.08        98\n",
      "              military       0.69      0.33      0.45       216\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.79      0.61      0.69       407\n",
      "                  food       0.80      0.70      0.75       746\n",
      "               shelter       0.77      0.52      0.62       582\n",
      "              clothing       0.63      0.43      0.51        91\n",
      "                 money       0.52      0.24      0.33       158\n",
      "        missing_people       0.69      0.24      0.35        85\n",
      "              refugees       0.73      0.19      0.31       222\n",
      "                 death       0.76      0.42      0.54       311\n",
      "             other_aid       0.54      0.15      0.23       894\n",
      "infrastructure_related       0.49      0.08      0.14       400\n",
      "             transport       0.67      0.30      0.41       274\n",
      "             buildings       0.65      0.39      0.49       285\n",
      "           electricity       0.58      0.22      0.32       135\n",
      "                 tools       0.17      0.03      0.05        37\n",
      "             hospitals       0.37      0.15      0.22        71\n",
      "                 shops       0.00      0.00      0.00        34\n",
      "           aid_centers       0.21      0.07      0.11        70\n",
      "  other_infrastructure       0.36      0.07      0.12       261\n",
      "       weather_related       0.85      0.66      0.74      1788\n",
      "                floods       0.86      0.54      0.66       491\n",
      "                 storm       0.77      0.46      0.58       634\n",
      "                  fire       0.55      0.36      0.44        66\n",
      "            earthquake       0.88      0.76      0.82       594\n",
      "                  cold       0.58      0.35      0.44       124\n",
      "         other_weather       0.49      0.14      0.22       360\n",
      "         direct_report       0.73      0.47      0.57      1297\n",
      "\n",
      "             micro avg       0.78      0.58      0.67     20674\n",
      "             macro avg       0.57      0.33      0.40     20674\n",
      "          weighted avg       0.74      0.58      0.63     20674\n",
      "           samples avg       0.65      0.51      0.52     20674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/workspaces/disaster-response-pipeline-uda/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print the 'accuracy report' for the 'test data'\n",
    "print(classification_report(y_test.values, y_prediction_from_test_data, target_names=y.columns.values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/disaster-response-pipeline-uda/Piplines'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wb' write in 'binary mode'\n",
    "with open('mo2.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `models/train_classifier.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
